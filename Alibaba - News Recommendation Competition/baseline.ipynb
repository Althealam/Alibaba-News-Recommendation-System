{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9573489,"sourceType":"datasetVersion","datasetId":5835808}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 导包","metadata":{}},{"cell_type":"code","source":"# import packages\nimport time, math, os\nfrom tqdm import tqdm\nimport gc\nimport pickle\nimport random\nfrom datetime import datetime\nfrom operator import itemgetter\nimport numpy as np\nimport pandas as pd\nimport warnings\nfrom collections import defaultdict\nimport collections\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-15T06:11:47.534080Z","iopub.execute_input":"2024-10-15T06:11:47.534453Z","iopub.status.idle":"2024-10-15T06:11:47.918161Z","shell.execute_reply.started":"2024-10-15T06:11:47.534416Z","shell.execute_reply":"2024-10-15T06:11:47.917328Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data_path='/kaggle/input/news-recommendation-dataset/'\nsave_path='/kaggle/working/'","metadata":{"execution":{"iopub.status.busy":"2024-10-15T06:11:47.919913Z","iopub.execute_input":"2024-10-15T06:11:47.920735Z","iopub.status.idle":"2024-10-15T06:11:47.924894Z","shell.execute_reply.started":"2024-10-15T06:11:47.920685Z","shell.execute_reply":"2024-10-15T06:11:47.923944Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## df节省内存函数","metadata":{}},{"cell_type":"code","source":"# 节约内存的一个标配函数\ndef reduce_mem(df):\n    starttime = time.time()\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if pd.isnull(c_min) or pd.isnull(c_max):\n                continue\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('-- Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction),time spend:{:2.2f} min'.format(end_mem,\n                                                                                                           100*(start_mem-end_mem)/start_mem,\n                                                                                                           (time.time()-starttime)/60))\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-10-15T06:11:47.926159Z","iopub.execute_input":"2024-10-15T06:11:47.926589Z","iopub.status.idle":"2024-10-15T06:11:47.940025Z","shell.execute_reply.started":"2024-10-15T06:11:47.926557Z","shell.execute_reply":"2024-10-15T06:11:47.939224Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## 读取采样或全量数据","metadata":{}},{"cell_type":"code","source":"# debug模式：从训练集中划出一部分数据来调试代码\ndef get_all_click_sample(data_path, sample_nums=10000):\n    \"\"\"\n        从完整的训练集中采样一部份数据，用于调试和开发过程中快速迭代和测试\n        data_path: 原数据的存储路径\n        sample_nums: 采样数量\n    \"\"\"\n    # 读取训练点击日志\n    all_click = pd.read_csv(data_path + 'train_click_log.csv')\n    # 获取所有独立用户ID\n    all_user_ids = all_click.user_id.unique()\n    \n    # 随机采样用户\n    sample_user_ids = np.random.choice(all_user_ids, size=sample_nums, replace=False) \n    # 筛选用户的点击数据\n    all_click = all_click[all_click['user_id'].isin(sample_user_ids)]\n    \n    # 去重\n    all_click = all_click.drop_duplicates((['user_id', 'click_article_id', 'click_timestamp']))\n    return all_click\n\n# 读取点击数据，这里分成线上和线下，如果是为了获取线上提交结果应该讲测试集中的点击数据合并到总的数据中\n# 如果是为了线下验证模型的有效性或者特征的有效性，可以只使用训练集\ndef get_all_click_df(data_path='/kaggle/input/news-recommendation-dataset/', offline=True):\n    \"\"\"\n        根据是否处理离线状态，读取并准备完整的点击数据集\n        :param data_path：存储原始数据文件的路径\n        :param offline：指示是否处于离线模式。在离线模式下只使用训练集      \n    \"\"\"\n    if offline: # 离线模式--只读取训练集的点击数据\n        all_click = pd.read_csv(data_path + 'train_click_log.csv')\n    else: # 在线模式--读取训练集和测试集的点击数据\n        trn_click = pd.read_csv(data_path + 'train_click_log.csv')\n        tst_click = pd.read_csv(data_path + 'testA_click_log.csv')\n\n        all_click = pd.concat([tst_click,trn_click])\n    \n    all_click = all_click.drop_duplicates((['user_id', 'click_article_id', 'click_timestamp']))\n    return all_click","metadata":{"execution":{"iopub.status.busy":"2024-10-15T06:11:47.942298Z","iopub.execute_input":"2024-10-15T06:11:47.942665Z","iopub.status.idle":"2024-10-15T06:11:47.953820Z","shell.execute_reply.started":"2024-10-15T06:11:47.942607Z","shell.execute_reply":"2024-10-15T06:11:47.953061Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# 全量训练集\nall_click_df = get_all_click_df(data_path, offline=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-15T06:11:47.954940Z","iopub.execute_input":"2024-10-15T06:11:47.955213Z","iopub.status.idle":"2024-10-15T06:11:50.767710Z","shell.execute_reply.started":"2024-10-15T06:11:47.955182Z","shell.execute_reply":"2024-10-15T06:11:50.766686Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## 获取 用户-文章-点击时间 字典","metadata":{}},{"cell_type":"code","source":"# 根据点击时间获取用户的点击文章序列   {user1: [(item1, time1), (item2, time2)..]...}\ndef get_user_item_time(click_df):\n    \n    click_df = click_df.sort_values('click_timestamp')\n    \n    def make_item_time_pair(df):\n        return list(zip(df['click_article_id'], df['click_timestamp']))\n    \n    user_item_time_df = click_df.groupby('user_id')[['click_article_id', 'click_timestamp']].apply(lambda x: make_item_time_pair(x))\\\n                                                            .reset_index().rename(columns={0: 'item_time_list'})\n    user_item_time_dict = dict(zip(user_item_time_df['user_id'], user_item_time_df['item_time_list']))\n    \n    return user_item_time_dict","metadata":{"execution":{"iopub.status.busy":"2024-10-15T06:11:50.769211Z","iopub.execute_input":"2024-10-15T06:11:50.769917Z","iopub.status.idle":"2024-10-15T06:11:50.776230Z","shell.execute_reply.started":"2024-10-15T06:11:50.769880Z","shell.execute_reply":"2024-10-15T06:11:50.775143Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## 获取点击最多的topk个文件","metadata":{}},{"cell_type":"code","source":"# 获取近期点击最多的文章\ndef get_item_topk_click(click_df, k):\n    topk_click = click_df['click_article_id'].value_counts().index[:k]\n    return topk_click","metadata":{"execution":{"iopub.status.busy":"2024-10-15T06:11:50.777238Z","iopub.execute_input":"2024-10-15T06:11:50.777489Z","iopub.status.idle":"2024-10-15T06:11:50.788026Z","shell.execute_reply.started":"2024-10-15T06:11:50.777461Z","shell.execute_reply":"2024-10-15T06:11:50.787123Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## itemcf的物品相似度计算","metadata":{}},{"cell_type":"code","source":"def itemcf_sim(df):\n    \"\"\"\n        文章与文章之间的相似性矩阵计算\n        :param df: 数据表\n        :item_created_time_dict:  文章创建时间的字典\n        return : 文章与文章的相似性矩阵\n        思路: 基于物品的协同过滤(详细请参考上一期推荐系统基础的组队学习)， 在多路召回部分会加上关联规则的召回策略\n    \"\"\"\n    \n    user_item_time_dict = get_user_item_time(df)\n    \n    # 计算物品相似度\n    i2i_sim = {}\n    item_cnt = defaultdict(int)\n    for user, item_time_list in tqdm(user_item_time_dict.items()):\n        # 在基于商品的协同过滤优化的时候可以考虑时间因素\n        for i, i_click_time in item_time_list:\n            item_cnt[i] += 1\n            i2i_sim.setdefault(i, {})\n            for j, j_click_time in item_time_list:\n                if(i == j):\n                    continue\n                i2i_sim[i].setdefault(j, 0)\n                \n                i2i_sim[i][j] += 1 / math.log(len(item_time_list) + 1)\n                \n    i2i_sim_ = i2i_sim.copy()\n    for i, related_items in i2i_sim.items():\n        for j, wij in related_items.items():\n            i2i_sim_[i][j] = wij / math.sqrt(item_cnt[i] * item_cnt[j])\n    \n    # 将得到的相似性矩阵保存到本地\n    pickle.dump(i2i_sim_, open(save_path + 'itemcf_i2i_sim.pkl', 'wb'))\n    \n    return i2i_sim_","metadata":{"execution":{"iopub.status.busy":"2024-10-15T06:11:50.789076Z","iopub.execute_input":"2024-10-15T06:11:50.789413Z","iopub.status.idle":"2024-10-15T06:11:50.799883Z","shell.execute_reply.started":"2024-10-15T06:11:50.789369Z","shell.execute_reply":"2024-10-15T06:11:50.799161Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"i2i_sim = itemcf_sim(all_click_df)","metadata":{"execution":{"iopub.status.busy":"2024-10-15T06:11:50.801021Z","iopub.execute_input":"2024-10-15T06:11:50.801298Z","iopub.status.idle":"2024-10-15T06:12:54.624000Z","shell.execute_reply.started":"2024-10-15T06:11:50.801268Z","shell.execute_reply":"2024-10-15T06:12:54.623197Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"100%|██████████| 250000/250000 [00:33<00:00, 7378.14it/s] \n","output_type":"stream"}]},{"cell_type":"markdown","source":"## itemcf的文章推荐","metadata":{}},{"cell_type":"code","source":"# 基于商品的召回i2i\ndef item_based_recommend(user_id, user_item_time_dict, i2i_sim, sim_item_topk, recall_item_num, item_topk_click):\n    \"\"\"\n        基于文章协同过滤的召回\n        :param user_id: 用户id\n        :param user_item_time_dict: 字典, 根据点击时间获取用户的点击文章序列   {user1: [(item1, time1), (item2, time2)..]...}\n        :param i2i_sim: 字典，文章相似性矩阵\n        :param sim_item_topk: 整数， 选择与当前文章最相似的前k篇文章\n        :param recall_item_num: 整数， 最后的召回文章数量\n        :param item_topk_click: 列表，点击次数最多的文章列表，用户召回补全        \n        return: 召回的文章列表 {item1:score1, item2: score2...}\n        注意: 基于物品的协同过滤(详细请参考上一期推荐系统基础的组队学习)， 在多路召回部分会加上关联规则的召回策略\n    \"\"\"\n    \n    # 获取用户的历史点击文章列表\n    user_hist_items = user_item_time_dict[user_id]\n    user_hist_items_ = {user_id for user_id, _ in user_hist_items}\n    \n    # 初始化召回文章的得分字典（用于存储召回的文章及其相应的得分）\n    item_rank = {}\n    # 基于物品相似性进行召回\n    for loc, (i, click_time) in enumerate(user_hist_items):\n        # user_hist_items: {user1:[(item1:time1),(item2:time2),...],user2:...}\n        # enumerate函数用于获取用户历史点击的索引，和每篇文章的id以及点击时间\n        # i2i_sim是物品相似性矩阵，抱歉了当前文章i与其他所有文章的相似度得分\n        # sorted(i2i_sim[i].items(), key=lambda x: x[1], reverse=True)：将这些键值对按照相似度得分（每个元组的第二个元素，即x[1]，也就是相似度得分）降序排序\n        # 从排序后的列表中取出相似度最高的前sim_item_topk个文章\n        for j, wij in sorted(i2i_sim[i].items(), key=lambda x: x[1], reverse=True)[:sim_item_topk]:\n            # wij表示文章i与文章j的相似度得分\n            # 过滤用户已点击的文章\n            if j in user_hist_items_:\n                continue\n            \n            # 用户没点击过的文章\n            item_rank.setdefault(j, 0) # 添加到item_rank字典中\n            item_rank[j] +=  wij # 累加他们的相似度得分\n    \n    # 使用热门文章进行补全\n    if len(item_rank) < recall_item_num:\n        for i, item in enumerate(item_topk_click):\n            if item in item_rank.items(): # 填充的item应该不在原来的列表中\n                continue\n            item_rank[item] = - i - 100 # 随便给个负数就行\n            if len(item_rank) == recall_item_num:\n                break\n    \n    # 将item_rank中的文章按照得分降序排序\n    # 截取排序后的列表中的前recall_item_num篇文章作为最终召回结果\n    item_rank = sorted(item_rank.items(), key=lambda x: x[1], reverse=True)[:recall_item_num]\n        \n    return item_rank","metadata":{"execution":{"iopub.status.busy":"2024-10-15T06:12:54.627338Z","iopub.execute_input":"2024-10-15T06:12:54.627716Z","iopub.status.idle":"2024-10-15T06:12:54.638167Z","shell.execute_reply.started":"2024-10-15T06:12:54.627681Z","shell.execute_reply":"2024-10-15T06:12:54.637061Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## 给每个用户根据物品的协同过滤推荐文章","metadata":{}},{"cell_type":"code","source":"# 定义\nuser_recall_items_dict = collections.defaultdict(dict)\n\n# 获取 用户 - 文章 - 点击时间的字典\nuser_item_time_dict = get_user_item_time(all_click_df)\n\n# 去取文章相似度\ni2i_sim = pickle.load(open(save_path + 'itemcf_i2i_sim.pkl', 'rb'))\n\n# 相似文章的数量\nsim_item_topk = 10\n\n# 召回文章数量\nrecall_item_num = 10\n\n# 用户热度补全\nitem_topk_click = get_item_topk_click(all_click_df, k=50)\n\nfor user in tqdm(all_click_df['user_id'].unique()):\n    user_recall_items_dict[user] = item_based_recommend(user, user_item_time_dict, i2i_sim, \n                                                        sim_item_topk, recall_item_num, item_topk_click)","metadata":{"execution":{"iopub.status.busy":"2024-10-15T06:12:54.639406Z","iopub.execute_input":"2024-10-15T06:12:54.639758Z","iopub.status.idle":"2024-10-15T06:56:24.085911Z","shell.execute_reply.started":"2024-10-15T06:12:54.639727Z","shell.execute_reply":"2024-10-15T06:56:24.084955Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"100%|██████████| 250000/250000 [43:04<00:00, 96.74it/s] \n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 召回字典转换成df","metadata":{}},{"cell_type":"code","source":"# 将字典的形式转换成df\nuser_item_score_list = []\n\nfor user, items in tqdm(user_recall_items_dict.items()):\n    for item, score in items:\n        user_item_score_list.append([user, item, score])\n\nrecall_df = pd.DataFrame(user_item_score_list, columns=['user_id', 'click_article_id', 'pred_score'])","metadata":{"execution":{"iopub.status.busy":"2024-10-15T06:56:24.087178Z","iopub.execute_input":"2024-10-15T06:56:24.087464Z","iopub.status.idle":"2024-10-15T06:56:38.834028Z","shell.execute_reply.started":"2024-10-15T06:56:24.087433Z","shell.execute_reply":"2024-10-15T06:56:38.832998Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"100%|██████████| 250000/250000 [00:05<00:00, 49593.77it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 生成提交文件","metadata":{}},{"cell_type":"code","source":"def submit(recall_df,topk=5,model_name=None):\n    recall_df=recall_df.sort_values(by=['user_id','pred_score'])\n    recall_df['rank']=recall_df.groupby(['user_id'])['pred_score'].rank(ascending=False,method='first')\n    \n    # 判断是不是每个用户都有5篇文章及以上\n    tmp=recall_df.groupby('user_id').apply(lambda x: x['rank'].max())\n    assert tmp.min()>=topk\n    \n    del recall_df['pred_score']\n    submit=recall_df[recall_df['rank']<=topk].set_index(['user_id','rank']).unstack(-1).reset_index()\n    \n    submit.columns=[int(col) if isinstance(col,int) else col for col in submit.columns.droplevel(0)]\n    # 按照提交格式定义列名\n    submit=submit.rename(columns={'':'user_id',1:'article_1',2:'article_2',3:'article_3',4:'article_4',5:'article_5'})\n    \n    save_name=save_path+model_name+'_'+datetime.today().strftime('%m-%d')+'.csv'\n\n    submit.to_csv(save_name,index=False,header=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-15T06:56:38.835389Z","iopub.execute_input":"2024-10-15T06:56:38.835788Z","iopub.status.idle":"2024-10-15T06:56:38.844768Z","shell.execute_reply.started":"2024-10-15T06:56:38.835744Z","shell.execute_reply":"2024-10-15T06:56:38.843788Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# 获取测试集\ntst_click=pd.read_csv(data_path+'testA_click_log.csv')\ntst_users=tst_click['user_id'].unique()\n\n# 从所有的召回数据中将测试集中的用户选出来\ntst_recall=recall_df[recall_df['user_id'].isin(tst_users)]\n\n# 生成提交文件\nsubmit(tst_recall,topk=5,model_name='itemcf_baseline')","metadata":{"execution":{"iopub.status.busy":"2024-10-15T07:02:25.345561Z","iopub.execute_input":"2024-10-15T07:02:25.345958Z","iopub.status.idle":"2024-10-15T07:02:30.567143Z","shell.execute_reply.started":"2024-10-15T07:02:25.345921Z","shell.execute_reply":"2024-10-15T07:02:30.566220Z"},"trusted":true},"execution_count":14,"outputs":[]}]}